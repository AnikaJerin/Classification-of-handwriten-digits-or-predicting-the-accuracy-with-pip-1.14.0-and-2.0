# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OOkzr0ugjRCLOBJcnNuaZt_pXs7mFmws
"""

import tensorflow.compat.v1 as tf

tf.disable_v2_behavior()


#DOWNLOAD DATASET
#this is nothing but a lightweight class which stores the training validation and testing set as numpy
from tensorflow.examples.tutorials.mnist import input_data


mnist=input_data.read_data_sets('MNIST_data',one_hot=True) #one_hot+True is nothing but 100 encoded..encoding means if I classify something as 7 then I am gonna 
#represent that as 0000000100(0-9)..it means only 1 output is active at a time
#start the session
sess=tf.compat.v1.InteractiveSession()
#we'll build a computational graph by creating nodes for the input images and target output classes
x=tf.placeholder(tf.float32,shape=[None,784]) #the input image x will consist of 2D tensors of floating point numbers..784 is the single dimansionality of single
#flat and 28by28 pixel og mnest image of handwritten digits..None indicates the 1st dimension corresponding to the batch size can be of any size that means
#1st dimension can be of any size
y= tf.placeholder(tf.float32,shape=[None,10])#desired outputs..10 bacause of 10 classes we have

#define a bias and weight for our model
w=tf.Variable(tf.zeros([784,10])) #initialize the variable to 0
b=tf.Variable(tf.zeros([10]))#bias

#we pass an initial value for each parameter in the call.w is 784X10 matrix because we have 784 input features and 10 outputs and b is a 10 dimansional vector because we 
#have 10 classes

#before we can use variables in a session we have to first initialize it
sess.run(tf.global_variables_initializer())

#next task predict the class and loss function
#we are gonna implement our regression model. It takes only one line. We multiply the vectorized input imade x by the weight matrix w and add the bias
y_=tf.matmul(x,w)+b
#specifying loss function that indicates how bad was the modle's prediction was on single example. we'll try to minimize that while training accross all the examples
cross_entropy=tf.reduce_mean(
    tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=y_)#label=target output,logits=actual output
    #here it just calculating the diff between target and actual outputs for all examples,then sum all of them and find out the mean
)

#now we need to train our model
#here the learning rate or hthe stape length will be .5
train_step=tf.train.GradientDescentOptimizer(0.5).minimizer(cross_entropy) #it'll minimize the ce which is nothing but a loss function

#next step is loading 100 training examples in each training iteration
#after that we will use a feed_dict to replace the placeholder tensors x and y with the training examples. basically x will contain the input images and y will
#contain the actual outputs or desired outputs
for _ in range(1000):
  batch=mnist.train.next_batch(100)
  train_step.run(feed_dict={x:batch[0],y:batch[1]})

#now we need to evaluate our model. we need to figure out how well our model is doing
#for that use tf.argmax func
correct_prediction=tf.equal(tf.argmax(y_,1),tf.argmax(y,1)) #tf.equal func is checking if our desired prediction mathces the actual prediction

#we are gonna calculate the accuracy to determine what fraction are correct, we cast a floating point numb and take the mean
accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))#defining a variable for accuracy

#we'll evaluate our accuracy on the test data
#this should give us accuracy for about 90%
print(accuracy.eval(feed_dict={x:mnist.test.images,y:mnist.test.labels}))